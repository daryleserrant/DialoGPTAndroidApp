{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d9fa2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca535f83",
   "metadata": {},
   "source": [
    "# Step 1: Download Datasets\n",
    "\n",
    "Download the following datasets\n",
    "- Movie Dialogue Corpus: https://www.kaggle.com/datasets/Cornell-University/movie-dialog-corpus\n",
    "- Chatbot Dataset Topical Chat: https://www.kaggle.com/datasets/arnavsharmaas/chatbot-dataset-topical-chat\n",
    "- Human Conversation Training Data: https://www.kaggle.com/datasets/projjal1/human-conversation-training-data\n",
    "- Conversation Meetings: https://www.kaggle.com/datasets/gogogaurav95/conversation-meetings\n",
    "- Conversation JSON: https://www.kaggle.com/datasets/vaibhavgeek/conversation-json\n",
    "\n",
    "Create a new folder within the same directory of this notebook called raw_data and place the downloaded data in that folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e88020d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_conversation_rows(conversations):\n",
    "    '''\n",
    "    Reshapes a list of dialogue between two individuals/entites into 1 or more rows of dialogue.\n",
    "    Each row consists of response and the previous 6 responses which serves as context for the DialoGPT\n",
    "    chatbot\n",
    "    '''\n",
    "    rows = []\n",
    "    if len(conversations) > 7:\n",
    "        for i in range(7, len(conversations)):\n",
    "            rows.append(conversations[i-7:i+1][::-1])\n",
    "    return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4c93419",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_conversation_json():\n",
    "    '''\n",
    "    Parses the Conversation JSON file and returns a list of conversation rows\n",
    "    '''\n",
    "    with open('raw_data/conversation.json') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    rows = []\n",
    "    for conversation in data['conversations']:\n",
    "        newrows = create_conversation_rows(conversation)\n",
    "        for row in newrows:\n",
    "            rows.append(row)\n",
    "    return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f5cb21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_conversation_txt(filepath):\n",
    "    '''\n",
    "    Parses the text files from the following datasets:\n",
    "      - Human Conversation Training Dataset\n",
    "      - Conversation Meetings Dataset\n",
    "    \n",
    "    Returns a list of conversational rows\n",
    "    '''\n",
    "    with open(filepath, encoding='utf8') as f:\n",
    "        conversation = []\n",
    "        data = f.read().split('\\n')\n",
    "        for line in data:\n",
    "            if line != '':\n",
    "                conversation.append(line.replace(\"Tom:\",\"\")\\\n",
    "                                    .replace(\"Anna:\",\"\")\\\n",
    "                                    .replace(\"Lynn: \",\"\")\\\n",
    "                                    .replace(\"Jane: \",\"\")\\\n",
    "                                    .replace(\"Human 1:\",\"\")\\\n",
    "                                    .replace(\"Human 2:\",\"\").strip()\\\n",
    "                                    .encode(encoding='ascii',errors='ignore').decode())\n",
    "    return create_conversation_rows(conversation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0905bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_topical_chat_csv(filepath):\n",
    "    '''\n",
    "    Parses the CSV file from the Topical Chat dataset and returns a list of conversation rows\n",
    "    '''\n",
    "    #read in file\n",
    "    df = pd.read_csv(filepath).dropna()\n",
    "        \n",
    "    newrows = df.groupby('conversation_id').apply((lambda grp: create_conversation_rows(grp['message'].tolist())))\n",
    "    results = []\n",
    "    for i in range(len(newrows)):\n",
    "        for row in newrows.iloc[i]:\n",
    "            results.append(row)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17e7f63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_movie_dialogue_corpus():\n",
    "    '''\n",
    "    Parses the entire movie dialog corpus and returns a list of conversation rows\n",
    "    '''\n",
    "    with open('raw_data/movie dialog corpus/movie_lines.tsv',encoding='utf8') as f:\n",
    "        data_lines = f.read().strip().split('\\n')\n",
    "        datarows = []\n",
    "        for line in data_lines:\n",
    "            elements = line.split('\\t')\n",
    "            row = {}\n",
    "            row['lineID'] =  elements[0].replace('\"',\"\")\n",
    "            row['characterID'] = elements[1]\n",
    "            row['movieID'] = elements[2]\n",
    "            row['characterName'] = elements[3]\n",
    "            row['text'] = \" \".join(elements[4:])\n",
    "            datarows.append(row)\n",
    "        movie_lines_df = pd.DataFrame(datarows).set_index('lineID')\n",
    "    movie_convos_df = pd.read_csv('raw_data/movie dialog corpus/movie_conversations.tsv', delimiter='\\t',header=None)  \n",
    "    movie_convos_df.columns = ['character1','character2','movieID','utterances']\n",
    "    results = []\n",
    "    for ix, row in movie_convos_df.iterrows():\n",
    "        utterance = row['utterances']\n",
    "        utterance = utterance.replace('[','').replace(']','').replace(\"'\",\"\").split(' ')\n",
    "        conversation = []\n",
    "        for lineID in utterance:\n",
    "            conversation.append(movie_lines_df.loc[lineID]['text'])\n",
    "        newrows = create_conversation_rows(conversation)\n",
    "        for row in newrows:\n",
    "            results.append(row)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9818e563",
   "metadata": {},
   "source": [
    "## Step Two: Parse Dataset Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cbc72344",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversations = []\n",
    "conversations.extend(parse_conversation_txt(\"raw_data/conversations2.txt\"))\n",
    "conversations.extend(parse_conversation_txt(\"raw_data/conversations3.txt\"))\n",
    "conversations.extend(parse_conversation_txt(\"raw_data/human_chat.txt\"))\n",
    "conversations.extend(parse_conversation_json())\n",
    "conversations.extend(parse_topical_chat_csv('raw_data/topical_chat.csv'))\n",
    "conversations.extend(parse_movie_dialogue_corpus())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ba67aa",
   "metadata": {},
   "source": [
    "## Step Three: Save Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29d01712",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.DataFrame(conversations, columns= ['response','context','context/0','context/1','context/2',\n",
    "                                                 'context/3','context/4','context/5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96c5e9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df2 = final_df[(final_df['response'] != '') & \n",
    "         (final_df['context'] != '') &\n",
    "         (final_df['context/0'] != '') &\n",
    "         (final_df['context/1'] != '') &\n",
    "         (final_df['context/2'] != '') &\n",
    "         (final_df['context/3'] != '') &\n",
    "         (final_df['context/4'] != '') &\n",
    "         (final_df['context/5'] != '')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe98900a",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df2.to_csv(\"final_conversations_dataset.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfccc82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
